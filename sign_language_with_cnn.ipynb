{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# Türkçe karakterleri ASCII uyumlu hale getir\n",
    "def normalize_filename(name):\n",
    "    name = unicodedata.normalize('NFKD', name)\n",
    "    return ''.join(c for c in name if not unicodedata.combining(c))\n",
    "\n",
    "def process_video(video_path, label, output_folder, json_data):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Video açılırken hata oluştu: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    frame_count = 0\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_filename = f\"{label}_{frame_count}.jpg\"\n",
    "        frame_path = os.path.join(output_folder, frame_filename)\n",
    "\n",
    "        try:\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            print(f\"Görsel kaydedildi: {frame_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Resim kaydedilirken hata oluştu: {e}\")\n",
    "            continue\n",
    "\n",
    "        frames.append({\n",
    "            \"image_path\": frame_path,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    json_data[label] = frames\n",
    "    print(f\"{label} etiketli video işlendi, {frame_count} kare kaydedildi.\")\n",
    "\n",
    "def save_json(json_data, output_json_path):\n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Veriler {output_json_path} dosyasına kaydedildi.\")\n",
    "    except Exception as e:\n",
    "        print(f\"JSON dosyasına yazılırken hata oluştu: {e}\")\n",
    "\n",
    "def process_videos(video_folder, output_folder, json_output_path):\n",
    "    json_data = {}\n",
    "\n",
    "    for video_name in os.listdir(video_folder):\n",
    "        if video_name.endswith(\".mp4\"):\n",
    "            label = os.path.splitext(video_name)[0]\n",
    "            label_normalized = normalize_filename(label)  # Türkçe karakterleri sadeleştir\n",
    "\n",
    "            video_path = os.path.join(video_folder, video_name)\n",
    "            print(f\"{video_name} işleniyor... (Etiket: {label_normalized})\")\n",
    "            process_video(video_path, label_normalized, output_folder, json_data)\n",
    "\n",
    "    save_json(json_data, json_output_path)\n",
    "\n",
    "# Ana çağrı\n",
    "if __name__ == \"__main__\":\n",
    "    video_folder = r\"İşaretDiliVideo\"\n",
    "    output_folder = r\"OutputImages\"\n",
    "    json_output_path = r\"output_data.json\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    process_videos(video_folder, output_folder, json_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21589b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8100\n",
      "Epoch 2, Loss: 0.8712\n",
      "Epoch 3, Loss: 0.3112\n",
      "Epoch 4, Loss: 0.1423\n",
      "Epoch 5, Loss: 0.0762\n",
      "Epoch 6, Loss: 0.0571\n",
      "Epoch 7, Loss: 0.0481\n",
      "Epoch 8, Loss: 0.0242\n",
      "Epoch 9, Loss: 0.0197\n",
      "Epoch 10, Loss: 0.0223\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneler içe aktarılıyor\n",
    "import os  # Dosya ve dizin işlemleri için\n",
    "import json  # JSON dosyalarını okumak ve yazmak için\n",
    "import cv2  # Görüntü işleme işlemleri için OpenCV\n",
    "import numpy as np  # Sayısal işlemler ve diziler için NumPy\n",
    "import torch  # PyTorch derin öğrenme kütüphanesi\n",
    "import torch.nn as nn  # Sinir ağı modülleri için\n",
    "import torch.optim as optim  # Optimizasyon algoritmaları için\n",
    "from torch.utils.data import DataLoader, Dataset  # Veri yükleyici ve özel veri kümesi sınıfı\n",
    "import speech_recognition as sr  # Ses tanıma işlemleri için\n",
    "import onnxruntime as ort  # ONNX modelini çalıştırmak için\n",
    "import typing  # Tip tanımlamaları için (örneğin Tuple)\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# === AnimeGAN Tanımı ===\n",
    "# Anime stilinde görüntü oluşturmak için kullanılan AnimeGAN sınıfı tanımlanıyor\n",
    "class AnimeGAN:\n",
    "    # Sınıfın kurucu fonksiyonu (init), model yolu ve boyut küçültme oranı alıyor\n",
    "    def __init__(self, model_path: str = '', downsize_ratio: float = 1.0):\n",
    "        # Model dosyasının var olup olmadığı kontrol ediliyor\n",
    "        if not os.path.exists(model_path):\n",
    "            raise Exception(f\"Model bulunamadı: {model_path}\")\n",
    "        \n",
    "        # Görüntüyü küçültmek için kullanılacak oran atanıyor\n",
    "        self.downsize_ratio = downsize_ratio\n",
    "        \n",
    "        # Modelin çalışacağı cihaz belirleniyor (GPU varsa GPU, yoksa CPU)\n",
    "        providers = ['CUDAExecutionProvider'] if ort.get_device() == \"GPU\" else ['CPUExecutionProvider']\n",
    "        \n",
    "        # ONNX model oturumu başlatılıyor\n",
    "        self.ort_sess = ort.InferenceSession(model_path, providers=providers)\n",
    "\n",
    "    # Görüntü boyutlarını 32'nin katına yuvarlayan yardımcı fonksiyon\n",
    "    def to_32s(self, x):\n",
    "        return 256 if x < 256 else x - x % 32\n",
    "\n",
    "    # Girdi görüntüsünü model için işleyen fonksiyon\n",
    "    def process_frame(self, frame: np.ndarray, x32: bool = True) -> np.ndarray:\n",
    "        h, w = frame.shape[:2]  # Yükseklik ve genişlik alınır\n",
    "        if x32:\n",
    "            frame = cv2.resize(frame, (self.to_32s(int(w * self.downsize_ratio)), self.to_32s(int(h * self.downsize_ratio))))\n",
    "        frame = frame.astype(np.float32) / 127.5 - 1.0  # Görüntü verisi -1 ile 1 aralığına ölçeklenir\n",
    "        return frame\n",
    "\n",
    "    # Model çıktılarını işleyerek tekrar orijinal formata dönüştürür\n",
    "    def post_process(self, frame: np.ndarray, wh: typing.Tuple[int, int]) -> np.ndarray:\n",
    "        frame = (frame.squeeze() + 1.) / 2 * 255  # -1 ile 1 aralığından 0-255'e normalize edilir\n",
    "        frame = frame.astype(np.uint8)  # Görüntü verisi uint8 formatına çevrilir\n",
    "        frame = cv2.resize(frame, (wh[0], wh[1]))  # Görüntü orijinal boyuta getirilir\n",
    "        return frame\n",
    "\n",
    "    # Sınıfın çağrıldığında çalışacak ana fonksiyonu\n",
    "    def __call__(self, frame: np.ndarray) -> np.ndarray:\n",
    "        image = self.process_frame(frame)  # Girdi görüntüsü işlenir\n",
    "        outputs = self.ort_sess.run(None, {self.ort_sess._inputs_meta[0].name: np.expand_dims(image, axis=0)})  # Model çalıştırılır\n",
    "        return self.post_process(outputs[0], frame.shape[:2][::-1])  # Çıktı işlenip geri döndürülür\n",
    "\n",
    "# === Veri ve Model Yolları ===\n",
    "# JSON veri dosyasının ve resimlerin yolu tanımlanıyor\n",
    "json_path = r\"output_data.json\"\n",
    "image_folder = r\"OutputImages\"\n",
    "animegan_model_path = r\"animegan.onnx\"  # ONNX model dosyasının yolu\n",
    "\n",
    "# === Dataset Sınıfı ===\n",
    "# İşaret dili veri kümesi için özel bir PyTorch Dataset sınıfı\n",
    "class SignLanguageDataset(Dataset):\n",
    "    # Kurucu fonksiyon; JSON dosyasını yükler ve verileri hazırlar\n",
    "    def __init__(self, json_path, image_size=(64, 64)):\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)  # JSON verisi yüklenir\n",
    "        \n",
    "        self.image_paths = []  # İşlenecek görüntülerin listesi\n",
    "        self.labels = []  # Görüntülere karşılık gelen etiketler\n",
    "        self.label_map = {word: idx for idx, word in enumerate(self.data.keys())}  # Kelimelere sayısal etiket ataması\n",
    "\n",
    "        for word, frames in self.data.items():  # Her kelime ve ilgili kareleri döner\n",
    "            for frame in frames:  # Her kareyi işler\n",
    "                img_path = os.path.normpath(os.path.join(image_folder, os.path.basename(frame[\"image_path\"])))  # Resim yolu oluşturulur\n",
    "                if os.path.exists(img_path):  # Dosya mevcutsa\n",
    "                    img = cv2.imread(img_path)  # Görüntü okunur\n",
    "                    if img is not None:  # Görüntü başarıyla yüklendiyse\n",
    "                        img = cv2.resize(img, image_size)  # Yeniden boyutlandırılır\n",
    "                        img = img / 255.0  # 0-1 aralığına normalize edilir\n",
    "                        self.image_paths.append(img)  # Görüntü listeye eklenir\n",
    "                        self.labels.append(self.label_map[word])  # Etiket listeye eklenir\n",
    "                    else:\n",
    "                        print(f\"Resim yüklenemedi: {img_path}\")\n",
    "                else:\n",
    "                    print(f\"Dosya yok: {img_path}\")\n",
    "\n",
    "        self.image_paths = np.array(self.image_paths)  # Görüntü listesi NumPy dizisine çevrilir\n",
    "        self.labels = np.array(self.labels)  # Etiketler NumPy dizisine çevrilir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)  # Veri kümesinin uzunluğu\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.image_paths[idx]  # Belirtilen indeksdeki görüntü alınır\n",
    "        label = self.labels[idx]  # Etiketi alınır\n",
    "        img = np.transpose(img, (2, 0, 1))  # Kanal sırası PyTorch için (C, H, W) olacak şekilde düzenlenir\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.long)  # Tensör olarak döndürülür\n",
    "\n",
    "# === Model Tanımı ===\n",
    "# CNN (Convolutional Neural Network) tabanlı model tanımlanıyor\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()  # Üst sınıfın init fonksiyonu çağrılır\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # İlk konvolüsyon katmanı (3 kanal giriş, 32 filtre)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # İkinci konvolüsyon katmanı\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Havuzlama katmanı (2x2 boyutunda)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Tam bağlantılı katman\n",
    "        self.fc2 = nn.Linear(128, num_classes)  # Çıkış katmanı, sınıf sayısı kadar nöron\n",
    "        self.dropout = nn.Dropout(0.5)  # Aşırı öğrenmeyi engellemek için dropout uygulanır\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # İlk konvolüsyon ve aktivasyon + havuzlama\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # İkinci konvolüsyon ve aktivasyon + havuzlama\n",
    "        x = x.view(-1, 64 * 16 * 16)  # Tensör düzleştirilir (flatten)\n",
    "        x = torch.relu(self.fc1(x))  # Tam bağlantılı katman + aktivasyon\n",
    "        x = self.dropout(x)  # Dropout uygulanır\n",
    "        return self.fc2(x)  # Sonuç döndürülür\n",
    "\n",
    "# === Eğitim ve Veri Yükleme ===\n",
    "dataset = SignLanguageDataset(json_path)  # Veri kümesi oluşturulur\n",
    "train_size = int(0.8 * len(dataset))  # %80 eğitim, %20 test verisi olarak ayrılır\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])  # Veri kümesi bölünür\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Eğitim verisi için yükleyici\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Test verisi için yükleyici\n",
    "\n",
    "num_classes = len(dataset.label_map)  # Sınıf sayısı veri kümesinden alınır\n",
    "model = CNNModel(num_classes)  # Model oluşturulur\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Kayıp fonksiyonu (çok sınıflı sınıflandırma için)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizasyon algoritması\n",
    "\n",
    "# Eğitim döngüsü başlatılıyor\n",
    "for epoch in range(10):  # 10 dönem boyunca model eğitilecek\n",
    "    model.train()  # Eğitim moduna alınır\n",
    "    total_loss = 0  # Toplam kayıp sıfırlanır\n",
    "    for inputs, labels in train_loader:  # Tüm eğitim verileri döner\n",
    "        optimizer.zero_grad()  # Gradyanlar sıfırlanır\n",
    "        outputs = model(inputs)  # Model tahmin yapar\n",
    "        loss = criterion(outputs, labels)  # Kayıp hesaplanır\n",
    "        loss.backward()  # Geri yayılım yapılır\n",
    "        optimizer.step()  # Ağırlıklar güncellenir\n",
    "        total_loss += loss.item()  # Kayıp değeri toplanır\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")  # Epoch sonunda ortalama kayıp yazdırılır\n",
    "\n",
    "torch.save(model.state_dict(), 'cnn_sign_language_model.pth')  # Model dosyası kaydedilir\n",
    "\n",
    "# === Modeli Yükleme ===\n",
    "model.load_state_dict(torch.load('cnn_sign_language_model.pth'))  # Eğitimli model geri yüklenir\n",
    "model.eval()  # Değerlendirme moduna alınır\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "\n",
    "# === Türkçe Karakter Normalizasyon Fonksiyonu ===\n",
    "def normalize_text(text):\n",
    "    replacements = {\n",
    "        \"ç\": \"c\", \"ğ\": \"g\", \"ı\": \"i\", \"ö\": \"o\", \"ş\": \"s\", \"ü\": \"u\",\n",
    "        \"Ç\": \"C\", \"Ğ\": \"G\", \"İ\": \"I\", \"Ö\": \"O\", \"Ş\": \"S\", \"Ü\": \"U\"\n",
    "    }\n",
    "    for turkish_char, ascii_char in replacements.items():\n",
    "        text = text.replace(turkish_char, ascii_char)\n",
    "    return text\n",
    "\n",
    "# JSON'dan işlenmiş veri yükleme\n",
    "with open(\"processed_data.json\", \"r\") as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Görüntüleri baştan belleğe al\n",
    "cached_frames = {}\n",
    "for word, paths in processed_data.items():\n",
    "    cached_frames[word] = [cv2.imread(p) for p in paths]\n",
    "\n",
    "def real_time_sign_language():\n",
    "    words_queue = []\n",
    "    stop_listening = threading.Event()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Kamera açılamadı.\")\n",
    "        return\n",
    "\n",
    "    # Pencere ayarları\n",
    "    screen_width = 3000\n",
    "    screen_height = 1200\n",
    "    cv2.namedWindow(\"İşaret Dili Animasyonu\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"İşaret Dili Animasyonu\", screen_width, screen_height)\n",
    "    cv2.moveWindow(\"İşaret Dili Animasyonu\", 0, 0)\n",
    "\n",
    "    def listen_microphone():\n",
    "        recognizer = sr.Recognizer()\n",
    "        mic = sr.Microphone()\n",
    "\n",
    "        with mic as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        while not stop_listening.is_set():\n",
    "            with mic as source:\n",
    "                try:\n",
    "                    print(\" Konuşabilirsiniz...\")\n",
    "                    audio = recognizer.listen(source, timeout=3, phrase_time_limit=5)\n",
    "                    text = recognizer.recognize_google(audio, language=\"tr-TR\")\n",
    "                    words = text.split()\n",
    "                    if words:\n",
    "                        normalized_words = [normalize_text(w).capitalize() for w in words]\n",
    "                        words_queue.extend(normalized_words)\n",
    "                        print(f\" Algılandı: {' '.join(normalized_words)}\")\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\" Anlaşılamadı, lütfen tekrar edin...\")\n",
    "                except sr.RequestError:\n",
    "                    print(\" API hatası, internet bağlantınızı kontrol edin.\")\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    threading.Thread(target=listen_microphone, daemon=True).start()\n",
    "\n",
    "    print(\" Kamera başlatıldı. Konuştuğunuz kelimelerin işaret dilini gösterecek. Çıkmak için 'q' tuşuna basın...\")\n",
    "\n",
    "    current_word = \"\"\n",
    "    frame_list = []\n",
    "    last_word = \"\"\n",
    "    word_start_time = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Aynalama kaldırıldı (flip yok)\n",
    "        user_frame = cv2.resize(frame, (screen_width, screen_height))\n",
    "        anime_frame = np.zeros((500, 500, 3), dtype=np.uint8)\n",
    "\n",
    "        # Yeni kelime kuyruğu varsa ve animasyon yoksa\n",
    "        if words_queue and not frame_list:\n",
    "            current_word = words_queue.pop(0)\n",
    "            if current_word in cached_frames:\n",
    "                frame_list = cached_frames[current_word]\n",
    "                word_start_time = time.time()\n",
    "                last_word = current_word  # Son kelimeyi güncelle\n",
    "            else:\n",
    "                print(f\" Veri bulunamadı: {current_word}\")\n",
    "                frame_list = []\n",
    "\n",
    "        # Animasyon varsa zamanla göster\n",
    "        if frame_list:\n",
    "            frame_count = len(frame_list)\n",
    "            elapsed_time = (time.time() - word_start_time) * 75\n",
    "            index = int(elapsed_time)\n",
    "\n",
    "            if index < frame_count:\n",
    "                anime_frame = cv2.resize(frame_list[index], (500, 500))\n",
    "            else:\n",
    "                frame_list = []\n",
    "        elif last_word in cached_frames:\n",
    "            # Eğer yeni kelime algılanmadıysa, son kelimenin ilk karesi gösterilsin\n",
    "            anime_frame = cv2.resize(cached_frames[last_word][0], (500, 500))\n",
    "\n",
    "        # Anime frame'i sağ alt köşeye yerleştir\n",
    "        x_offset = screen_width - 500 - 20\n",
    "        y_offset = screen_height - 500 - 20\n",
    "        user_frame[y_offset:y_offset + 500, x_offset:x_offset + 500] = anime_frame\n",
    "\n",
    "        cv2.imshow(\"İşaret Dili Animasyonu\", user_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            stop_listening.set()\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\" Sistem durduruldu.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6966ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kamera başlatıldı. Konuştuğunuz kelimelerin işaret dilini gösterecek. Çıkmak için 'q' tuşuna basın...\n",
      " Konuşabilirsiniz...\n",
      " Algılandı: Merhaba\n",
      " Konuşabilirsiniz...\n",
      " Sistem durduruldu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Anlaşılamadı, lütfen tekrar edin...\n"
     ]
    }
   ],
   "source": [
    "# Canlı sistem başlat\n",
    "real_time_sign_language()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
