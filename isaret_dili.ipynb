{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e773f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anadolu etiketli video işleniyor...\n",
      "Anadolu etiketi için 88 kare işlendi, 88 keypoint dizisi kaydedildi.\n",
      "Araba etiketli video işleniyor...\n",
      "Araba etiketi için 86 kare işlendi, 86 keypoint dizisi kaydedildi.\n",
      "Arasinda etiketli video işleniyor...\n",
      "Arasinda etiketi için 123 kare işlendi, 123 keypoint dizisi kaydedildi.\n",
      "Artmak etiketli video işleniyor...\n",
      "Artmak etiketi için 103 kare işlendi, 103 keypoint dizisi kaydedildi.\n",
      "Avrupa etiketli video işleniyor...\n",
      "Avrupa etiketi için 85 kare işlendi, 85 keypoint dizisi kaydedildi.\n",
      "Aciklamada etiketli video işleniyor...\n",
      "Aciklamada etiketi için 112 kare işlendi, 112 keypoint dizisi kaydedildi.\n",
      "Baslamak etiketli video işleniyor...\n",
      "Baslamak etiketi için 74 kare işlendi, 74 keypoint dizisi kaydedildi.\n",
      "Belediye etiketli video işleniyor...\n",
      "Belediye etiketi için 94 kare işlendi, 94 keypoint dizisi kaydedildi.\n",
      "Belirtmek etiketli video işleniyor...\n",
      "Belirtmek etiketi için 96 kare işlendi, 96 keypoint dizisi kaydedildi.\n",
      "Ben etiketli video işleniyor...\n",
      "Ben etiketi için 72 kare işlendi, 72 keypoint dizisi kaydedildi.\n",
      "Bugun etiketli video işleniyor...\n",
      "Bugun etiketi için 97 kare işlendi, 97 keypoint dizisi kaydedildi.\n",
      "Gelismis etiketli video işleniyor...\n",
      "Gelismis etiketi için 84 kare işlendi, 84 keypoint dizisi kaydedildi.\n",
      "Gecis etiketli video işleniyor...\n",
      "Gecis etiketi için 97 kare işlendi, 97 keypoint dizisi kaydedildi.\n",
      "Hava etiketli video işleniyor...\n",
      "Hava etiketi için 97 kare işlendi, 97 keypoint dizisi kaydedildi.\n",
      "Kuyruk etiketli video işleniyor...\n",
      "Kuyruk etiketi için 106 kare işlendi, 106 keypoint dizisi kaydedildi.\n",
      "Kopru etiketli video işleniyor...\n",
      "Kopru etiketi için 77 kare işlendi, 77 keypoint dizisi kaydedildi.\n",
      "Kotu etiketli video işleniyor...\n",
      "Kotu etiketi için 86 kare işlendi, 86 keypoint dizisi kaydedildi.\n",
      "Merhaba etiketli video işleniyor...\n",
      "Merhaba etiketi için 141 kare işlendi, 141 keypoint dizisi kaydedildi.\n",
      "Olmak etiketli video işleniyor...\n",
      "Olmak etiketi için 89 kare işlendi, 89 keypoint dizisi kaydedildi.\n",
      "Olusmak etiketli video işleniyor...\n",
      "Olusmak etiketi için 88 kare işlendi, 88 keypoint dizisi kaydedildi.\n",
      "Proje etiketli video işleniyor...\n",
      "Proje etiketi için 114 kare işlendi, 114 keypoint dizisi kaydedildi.\n",
      "Saat etiketli video işleniyor...\n",
      "Saat etiketi için 89 kare işlendi, 89 keypoint dizisi kaydedildi.\n",
      "Sabah etiketli video işleniyor...\n",
      "Sabah etiketi için 78 kare işlendi, 78 keypoint dizisi kaydedildi.\n",
      "Sebep etiketli video işleniyor...\n",
      "Sebep etiketi için 67 kare işlendi, 67 keypoint dizisi kaydedildi.\n",
      "Surucu etiketli video işleniyor...\n",
      "Surucu etiketi için 91 kare işlendi, 91 keypoint dizisi kaydedildi.\n",
      "Tamir etiketli video işleniyor...\n",
      "Tamir etiketi için 74 kare işlendi, 74 keypoint dizisi kaydedildi.\n",
      "Trafik etiketli video işleniyor...\n",
      "Trafik etiketi için 83 kare işlendi, 83 keypoint dizisi kaydedildi.\n",
      "Uyarmak etiketli video işleniyor...\n",
      "Uyarmak etiketi için 70 kare işlendi, 70 keypoint dizisi kaydedildi.\n",
      "Uzman etiketli video işleniyor...\n",
      "Uzman etiketi için 130 kare işlendi, 130 keypoint dizisi kaydedildi.\n",
      "Uzun etiketli video işleniyor...\n",
      "Uzun etiketi için 84 kare işlendi, 84 keypoint dizisi kaydedildi.\n",
      "Vatandas etiketli video işleniyor...\n",
      "Vatandas etiketi için 88 kare işlendi, 88 keypoint dizisi kaydedildi.\n",
      "Ve etiketli video işleniyor...\n",
      "Ve etiketi için 61 kare işlendi, 61 keypoint dizisi kaydedildi.\n",
      "Yaka etiketli video işleniyor...\n",
      "Yaka etiketi için 82 kare işlendi, 82 keypoint dizisi kaydedildi.\n",
      "Yapmak etiketli video işleniyor...\n",
      "Yapmak etiketi için 70 kare işlendi, 70 keypoint dizisi kaydedildi.\n",
      "Yol etiketli video işleniyor...\n",
      "Yol etiketi için 76 kare işlendi, 76 keypoint dizisi kaydedildi.\n",
      "Zorlamak etiketli video işleniyor...\n",
      "Zorlamak etiketi için 62 kare işlendi, 62 keypoint dizisi kaydedildi.\n",
      "Ogrenci etiketli video işleniyor...\n",
      "Ogrenci etiketi için 104 kare işlendi, 104 keypoint dizisi kaydedildi.\n",
      "Universite etiketli video işleniyor...\n",
      "Universite etiketi için 70 kare işlendi, 70 keypoint dizisi kaydedildi.\n",
      "Istanbul etiketli video işleniyor...\n",
      "Istanbul etiketi için 86 kare işlendi, 86 keypoint dizisi kaydedildi.\n",
      "Sart etiketli video işleniyor...\n",
      "Sart etiketi için 60 kare işlendi, 60 keypoint dizisi kaydedildi.\n",
      "Simdi etiketli video işleniyor...\n",
      "Simdi etiketi için 76 kare işlendi, 76 keypoint dizisi kaydedildi.\n",
      "Veriler frame_data.json dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from mediapipe.python.solutions import hands as mp_hands\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "\n",
    "# Türkçe karakterleri ASCII uyumlu hale getir\n",
    "def normalize_filename(text):\n",
    "    replacements = {\n",
    "        \"ç\": \"c\", \"ğ\": \"g\", \"ı\": \"i\", \"ö\": \"o\", \"ş\": \"s\", \"ü\": \"u\",\n",
    "        \"Ç\": \"C\", \"Ğ\": \"G\", \"İ\": \"I\", \"Ö\": \"O\", \"Ş\": \"S\", \"Ü\": \"U\"\n",
    "    }\n",
    "    for turkish_char, ascii_char in replacements.items():\n",
    "        text = text.replace(turkish_char, ascii_char)\n",
    "    return text\n",
    "\n",
    "def process_video(video_path, label, json_data):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Video açılırken hata oluştu: {video_path}\")\n",
    "        return\n",
    "\n",
    "    keypoints_sequence = []  # Zamansal seriyi kaydetmek için diziler\n",
    "    frame_count = 0\n",
    "\n",
    "    with mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,  # İki eli algılamak için\n",
    "        min_detection_confidence=0.5\n",
    "    ) as hands, mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as pose:\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # RGB formatına dönüştür\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # MediaPipe Pose ve Hands ile işlem yap\n",
    "            hands_result = hands.process(image_rgb)\n",
    "            pose_result = pose.process(image_rgb)\n",
    "\n",
    "            # Tüm keypoint'leri birleştir\n",
    "            frame_keypoints = []\n",
    "\n",
    "            # El keypoints'lerini ekle\n",
    "            if hands_result.multi_hand_landmarks:\n",
    "                for hand_landmarks in hands_result.multi_hand_landmarks:\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        frame_keypoints.extend([lm.x, lm.y, lm.z])  # X, Y, Z koordinatları\n",
    "\n",
    "            # Vücut keypoints'lerini ekle\n",
    "            if pose_result.pose_landmarks:\n",
    "                for lm in pose_result.pose_landmarks.landmark:\n",
    "                    frame_keypoints.extend([lm.x, lm.y, lm.z])  # X, Y, Z koordinatları\n",
    "\n",
    "            # Eğer bu karede keypoint bulunduysa diziyi ekle\n",
    "            if frame_keypoints:\n",
    "                keypoints_sequence.append(frame_keypoints)\n",
    "\n",
    "            frame_count += 1  # Frame sayısını artır\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # JSON formatına ekle\n",
    "    json_data.append({\n",
    "        \"label\": label,\n",
    "        \"keypoints_sequence\": keypoints_sequence,\n",
    "        \"frame_count\": frame_count\n",
    "    })\n",
    "\n",
    "    print(f\"{label} etiketi için {frame_count} kare işlendi, {len(keypoints_sequence)} keypoint dizisi kaydedildi.\")\n",
    "\n",
    "def save_json(json_data, output_json_path):\n",
    "    try:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Veriler {output_json_path} dosyasına kaydedildi.\")\n",
    "    except Exception as e:\n",
    "        print(f\"JSON dosyasına yazılırken hata oluştu: {e}\")\n",
    "\n",
    "# Ana kod: Klasördeki tüm videoları işle ve JSON dosyasını kaydet\n",
    "def process_videos_in_folder(input_folder, output_json_path):\n",
    "    json_data = []  # JSON verilerini tutmak için liste\n",
    "\n",
    "    # Klasördeki tüm video dosyalarını işle\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        video_path = os.path.join(input_folder, file_name)\n",
    "        if not os.path.isfile(video_path):\n",
    "            continue  # Eğer dosya değilse, atla\n",
    "        if not file_name.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):  # Video formatları\n",
    "            continue  # Desteklenmeyen formatları atla\n",
    "\n",
    "        label = os.path.splitext(file_name)[0]  # Dosya adını etiket olarak kullan\n",
    "        label = normalize_filename(label)  # Türkçe karakterleri ASCII'ye çevir\n",
    "        print(f\"{label} etiketli video işleniyor...\")\n",
    "        process_video(video_path, label, json_data)\n",
    "\n",
    "    # JSON verisini kaydet\n",
    "    save_json(json_data, output_json_path)\n",
    "\n",
    "# Klasör yollarını tanımlayın\n",
    "input_folder = \"kökdata\"  # İşlenecek videoların bulunduğu klasör\n",
    "output_json_path = \"frame_data.json\"  # JSON dosyasının kaydedileceği dosya\n",
    "\n",
    "# Tüm videoları işle\n",
    "process_videos_in_folder(input_folder, output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae5c0b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# JSON verisini yükle\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_data.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Az örnekli sınıfları kontrol et ve filtrele\u001b[39;00m\n\u001b[0;32m     33\u001b[0m min_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Her sınıf için minimum örnek sayısı\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m, in \u001b[0;36mload_dataset_from_json\u001b[1;34m(json_path)\u001b[0m\n\u001b[0;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Etiketler\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, value \u001b[38;5;129;01min\u001b[39;00m raw_data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 22\u001b[0m     keypoints_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints_sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keypoints_sequence) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     24\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(keypoints_sequence)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# ===================== VERİ SETİ ===================== #\n",
    "\n",
    "# Veri yükleme fonksiyonu\n",
    "def load_dataset_from_json(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    X = []  # Keypoint dizileri\n",
    "    y = []  # Etiketler\n",
    "\n",
    "    for label, value in raw_data.items():\n",
    "        keypoints_sequence = value.get(\"keypoints_sequence\", [])\n",
    "        if len(keypoints_sequence) > 0:\n",
    "            X.append(keypoints_sequence)\n",
    "            y.append(label)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# JSON verisini yükle\n",
    "X, y = load_dataset_from_json(\"output_data.json\")\n",
    "\n",
    "# Az örnekli sınıfları kontrol et ve filtrele\n",
    "min_samples = 2  # Her sınıf için minimum örnek sayısı\n",
    "class_counts = Counter(y)\n",
    "\n",
    "X_filtered = []\n",
    "y_filtered = []\n",
    "for x, label in zip(X, y):\n",
    "    if class_counts[label] >= min_samples:  # Yeterli sayıda örneğe sahip sınıfları tut\n",
    "        X_filtered.append(x)\n",
    "        y_filtered.append(label)\n",
    "\n",
    "# Veri setini güncelle\n",
    "X = X_filtered\n",
    "y = y_filtered\n",
    "\n",
    "# Etiketleri encode et (String -> Integer)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Veriyi eğitim ve test için böl\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Tensor veri seti sınıfı\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, keypoints, labels):\n",
    "        self.keypoints = keypoints\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keypoints)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = np.array(self.keypoints[idx], dtype=np.float32)\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(sequence), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Dataset ve DataLoader\n",
    "train_dataset = KeypointDataset(X_train, y_train)\n",
    "test_dataset = KeypointDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# ===================== LSTM MODEL ===================== #\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)  # LSTM'nin son gizli durumu\n",
    "        out = self.fc(h_n[-1])      # Son gizli durumdan sınıf tahmini\n",
    "        return out\n",
    "\n",
    "# Model parametreleri\n",
    "input_size = 63  # Her frame için keypoints (21 landmark * 3 koordinat)\n",
    "hidden_size = 128  # LSTM gizli birim boyutu\n",
    "num_classes = len(le.classes_)  # Sınıf sayısı\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_classes)\n",
    "\n",
    "# ===================== EĞİTİM ===================== #\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Kayıp fonksiyonu\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizasyonu\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)  # Model tahmini\n",
    "        loss = criterion(outputs, y_batch)  # Kayıp hesaplama\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Doğruluk hesaplama\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    train_accuracy = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Eğitim tamamlandıktan sonra modeli kaydet\n",
    "torch.save(model.state_dict(), \"lstm_model.pth\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "print(\"Model ve LabelEncoder kaydedildi.\")\n",
    "\n",
    "# ===================== TEST ===================== #\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "test_accuracy = correct / total * 100\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14e4b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program kapatılıyor...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# MediaPipe eller modülü tanımlaması\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,  # Video akışı için statik görüntü modunda değil\n",
    "    max_num_hands=1,          # En fazla algılanacak el sayısı\n",
    "    min_detection_confidence=0.5,  # Minimum algılama güven eşiği\n",
    "    min_tracking_confidence=0.5    # Minimum takip güven eşiği\n",
    ")\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Model ve Label Encoder yükle\n",
    "input_size = 63\n",
    "le = joblib.load(\"label_encoder.pkl\")  # Etiket dönüştürücü (LabelEncoder)\n",
    "num_classes = len(le.classes_)  # Sınıf sayısını belirle\n",
    "model = SimpleMLP(input_size, num_classes)  # Modeli yeniden oluştur\n",
    "model.load_state_dict(torch.load(\"model.pth\"))  # Ağırlıkları yükle\n",
    "model.eval()  # Modeli değerlendirme moduna al\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand = results.multi_hand_landmarks[0]\n",
    "        keypoints = []\n",
    "        for lm in hand.landmark:\n",
    "            keypoints.extend([lm.x, lm.y, lm.z])\n",
    "        return keypoints\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Kamera açılır\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Kamera açılamıyor. Lütfen cihazınızın kamerasını kontrol edin.\")\n",
    "    exit()  # Programdan çıkış\n",
    "\n",
    "sequence = []\n",
    "seq_length = 30\n",
    "predicted_label = \"\"\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Kamera akışı sağlanamadı. Program kapatılıyor...\")\n",
    "            break\n",
    "\n",
    "        # Görüntüyü ters çevir ve işle\n",
    "        image = cv2.flip(frame, 1)\n",
    "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(img_rgb)  # MediaPipe işlemi başlat\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(image, results.multi_hand_landmarks[0], mp_hands.HAND_CONNECTIONS)\n",
    "            keypoints = extract_keypoints(results)\n",
    "\n",
    "            if keypoints:\n",
    "                sequence.append(keypoints)\n",
    "                if len(sequence) > seq_length:\n",
    "                    sequence.pop(0)\n",
    "\n",
    "                if len(sequence) == seq_length:\n",
    "                    # Modele uygun forma getir\n",
    "                    input_tensor = torch.tensor(sequence[-1], dtype=torch.float32).view(1, -1)  # Tensor boyutunu düzelt\n",
    "                    with torch.no_grad():\n",
    "                        prediction = model(input_tensor)\n",
    "                        predicted_class = torch.argmax(prediction, dim=1).item()\n",
    "                        predicted_label = le.inverse_transform([predicted_class])[0]\n",
    "\n",
    "        # Ekrana tahmini yaz\n",
    "        cv2.putText(image, f\"Tahmin: {predicted_label}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Tahmin\", image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q' ile çıkış kontrolü\n",
    "            print(\"Program kapatılıyor...\")\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"Bir hata oluştu: {e}\")\n",
    "finally:\n",
    "    cap.release()  # Kamera serbest bırakılır\n",
    "    cv2.destroyAllWindows()  # Tüm pencereler kapatılır\n",
    "    hands.close()  # MediaPipe elleri kapatılır"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
