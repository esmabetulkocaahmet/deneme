{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816d5245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneler import ediliyor\n",
    "import os  # Dosya ve klasÃ¶r iÅŸlemleri iÃ§in\n",
    "import json  # JSON formatÄ±ndaki verileri okuyup yazmak iÃ§in\n",
    "import cv2  # OpenCV: GÃ¶rÃ¼ntÃ¼ iÅŸleme iÅŸlemleri iÃ§in\n",
    "import numpy as np  # SayÄ±sal iÅŸlemler ve dizi iÅŸlemleri iÃ§in\n",
    "import torch  # PyTorch: Derin Ã¶ÄŸrenme iÅŸlemleri iÃ§in\n",
    "import torch.nn as nn  # Yapay sinir aÄŸÄ± katmanlarÄ± iÃ§in\n",
    "import torch.optim as optim  # Model eÄŸitimi iÃ§in optimizasyon algoritmalarÄ±\n",
    "from torch.utils.data import DataLoader, Dataset  # Veri yÃ¼kleyici ve Ã¶zel veri seti sÄ±nÄ±fÄ± iÃ§in\n",
    "import typing  # TÃ¼r tanÄ±mlamalarÄ± iÃ§in (Ã¶rn. Tuple[int, int])\n",
    "import onnxruntime as ort  # ONNX formatÄ±ndaki modelleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in\n",
    "import speech_recognition as sr  # Sesli konuÅŸmayÄ± yazÄ±ya Ã§eviren kÃ¼tÃ¼phane\n",
    "\n",
    "# Anime stiline dÃ¶nÃ¼ÅŸtÃ¼rme sÄ±nÄ±fÄ± tanÄ±mlanÄ±yor\n",
    "class AnimeGAN:\n",
    "    def __init__(self, model_path: str = '', downsize_ratio: float = 1.0):  # YapÄ±cÄ± metod, model yolu ve boyut oranÄ± alÄ±r\n",
    "        self.model = ort.InferenceSession(model_path)  # ONNX model dosyasÄ± yÃ¼klenir\n",
    "        self.downsize_ratio = downsize_ratio  # Boyut kÃ¼Ã§Ã¼ltme oranÄ± kaydedilir\n",
    "\n",
    "    def to_32s(self, x):  # 32â€™nin katÄ± en yakÄ±n deÄŸeri dÃ¶ndÃ¼ren fonksiyon\n",
    "        return 256 if x < 256 else x - x % 32  # 32â€™nin katÄ± boyut ayarÄ± yapÄ±lÄ±r\n",
    "\n",
    "    def process_frame(self, frame: np.ndarray, x32: bool = True) -> np.ndarray:  # GÃ¶rseli modele uygun hale getirir\n",
    "        h, w = frame.shape[:2]  # YÃ¼kseklik ve geniÅŸlik alÄ±nÄ±r\n",
    "        if x32:\n",
    "            h, w = self.to_32s(h), self.to_32s(w)  # Boyutlar 32â€™nin katÄ± yapÄ±lÄ±r\n",
    "        frame = cv2.resize(frame, (w, h))  # GÃ¶rÃ¼ntÃ¼ yeniden boyutlandÄ±rÄ±lÄ±r\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.float32) / 127.5 - 1.0  # RGBâ€™ye Ã§evirilip normalize edilir\n",
    "        img = np.transpose(img, (2, 0, 1))  # Kanal boyutu en baÅŸa alÄ±nÄ±r (HWC -> CHW)\n",
    "        img = np.expand_dims(img, axis=0)  # Batch boyutu eklenir\n",
    "        return img  # Ä°ÅŸlenmiÅŸ tensÃ¶r dÃ¶ndÃ¼rÃ¼lÃ¼r\n",
    "\n",
    "    def post_process(self, frame: np.ndarray, wh: typing.Tuple[int, int]) -> np.ndarray:  # Model Ã§Ä±ktÄ±sÄ±nÄ± iÅŸleyip orijinal boyuta getirir\n",
    "        frame = np.squeeze(frame)  # Gereksiz boyut Ã§Ä±karÄ±lÄ±r (1,3,H,W -> 3,H,W)\n",
    "        frame = np.transpose(frame, (1, 2, 0))  # Kanal en sona alÄ±nÄ±r (CHW -> HWC)\n",
    "        frame = ((frame + 1.0) * 127.5).clip(0, 255).astype(np.uint8)  # Normalize geri alÄ±nÄ±r ve uint8 yapÄ±lÄ±r\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # BGR formatÄ±na Ã§evrilir\n",
    "        return cv2.resize(frame, wh)  # Orijinal boyuta dÃ¶ndÃ¼rÃ¼lÃ¼r\n",
    "\n",
    "    def __call__(self, frame: np.ndarray) -> np.ndarray:  # SÄ±nÄ±f Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda otomatik olarak stilize iÅŸlemini yapar\n",
    "        h, w = frame.shape[:2]  # GÃ¶rsel boyutlarÄ± alÄ±nÄ±r\n",
    "        input_tensor = self.process_frame(frame)  # GiriÅŸ tensÃ¶rÃ¼ hazÄ±rlanÄ±r\n",
    "        output = self.model.run(None, {'input': input_tensor})[0]  # Model tahmini alÄ±nÄ±r\n",
    "        return self.post_process(output, (w, h))  # Ã‡Ä±ktÄ± iÅŸlenip dÃ¶ndÃ¼rÃ¼lÃ¼r\n",
    "\n",
    "# Ä°ÅŸaret dili veri seti sÄ±nÄ±fÄ± tanÄ±mlanÄ±yor\n",
    "class SignLanguageDataset(Dataset):  # PyTorch Dataset sÄ±nÄ±fÄ±ndan tÃ¼retiliyor\n",
    "    def __init__(self, json_path, image_folder, image_size=(64, 64)):  # YapÄ±cÄ± metod\n",
    "        with open(json_path, 'r') as f:  # JSON dosyasÄ± aÃ§Ä±lÄ±r\n",
    "            self.data = json.load(f)  # JSON verisi yÃ¼klenir\n",
    "        self.image_paths = []  # GÃ¶rsel yollarÄ± tutulacak\n",
    "        self.labels = []  # Etiketler tutulacak\n",
    "        self.label_map = {word: idx for idx, word in enumerate(self.data.keys())}  # Kelime -> sayÄ± eÅŸleÅŸmesi\n",
    "        self.image_folder = image_folder  # GÃ¶rsel klasÃ¶rÃ¼ kaydedilir\n",
    "        self.image_size = image_size  # GÃ¶rsel boyutu kaydedilir\n",
    "\n",
    "        for word, filenames in self.data.items():  # TÃ¼m kelime ve gÃ¶rseller dolaÅŸÄ±lÄ±r\n",
    "            for filename in filenames:\n",
    "                self.image_paths.append(os.path.join(image_folder, filename))  # GÃ¶rsel yolu eklenir\n",
    "                self.labels.append(self.label_map[word])  # Etiketi eklenir\n",
    "\n",
    "    def __len__(self):  # Veri seti uzunluÄŸu\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):  # Belirli bir indeks iÃ§in veri dÃ¶ndÃ¼rÃ¼lÃ¼r\n",
    "        image_path = self.image_paths[idx]  # GÃ¶rsel yolu alÄ±nÄ±r\n",
    "        image = cv2.imread(image_path)  # GÃ¶rsel okunur\n",
    "        image = cv2.resize(image, self.image_size)  # Yeniden boyutlandÄ±rÄ±lÄ±r\n",
    "        image = image.transpose((2, 0, 1))  # Kanal en baÅŸa alÄ±nÄ±r (CHW)\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0  # Normalize edilip tensÃ¶re Ã§evrilir\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)  # Etiket tensÃ¶rÃ¼ alÄ±nÄ±r\n",
    "        return image, label  # GÃ¶rsel ve etiketi dÃ¶ndÃ¼rÃ¼lÃ¼r\n",
    "\n",
    "# Basit bir yapay sinir aÄŸÄ± (ANN) tanÄ±mlanÄ±yor\n",
    "class ANNModel(nn.Module):  # PyTorch sinir aÄŸÄ± modÃ¼lÃ¼nden tÃ¼retiliyor\n",
    "    def __init__(self, num_classes):  # YapÄ±cÄ± metod, sÄ±nÄ±f sayÄ±sÄ± alÄ±r\n",
    "        super(ANNModel, self).__init__()  # Ãœst sÄ±nÄ±f yapÄ±cÄ±sÄ± Ã§aÄŸrÄ±lÄ±r\n",
    "        self.flatten = nn.Flatten()  # 3D tensÃ¶rÃ¼ tek boyuta indirir\n",
    "        self.fc1 = nn.Linear(64 * 64 * 3, 256)  # GiriÅŸten 256 nÃ¶rona\n",
    "        self.relu1 = nn.ReLU()  # Aktivasyon fonksiyonu\n",
    "        self.fc2 = nn.Linear(256, 128)  # Orta katman\n",
    "        self.relu2 = nn.ReLU()  # Aktivasyon\n",
    "        self.fc3 = nn.Linear(128, num_classes)  # Ã‡Ä±kÄ±ÅŸ katmanÄ±\n",
    "\n",
    "    def forward(self, x):  # Ä°leri besleme iÅŸlemi\n",
    "        x = self.flatten(x)  # GÃ¶rseli dÃ¼zleÅŸtir\n",
    "        x = self.relu1(self.fc1(x))  # Ä°lk katman\n",
    "        x = self.relu2(self.fc2(x))  # Ä°kinci katman\n",
    "        x = self.fc3(x)  # Ã‡Ä±kÄ±ÅŸ katmanÄ±\n",
    "        return x  # Tahmin dÃ¶ndÃ¼rÃ¼lÃ¼r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# AnimeGAN sÄ±nÄ±fÄ± tanÄ±mlÄ± olmalÄ± (Ã¶nceden eklendiÄŸi gibi)\n",
    "onnx_model_path = r'animegan.onnx'\n",
    "animegan = AnimeGAN(model_path=onnx_model_path)  # AnimeGAN modeli yÃ¼klenir\n",
    "\n",
    "# === JSON VERÄ°SÄ° YÃœKLE ===\n",
    "with open(\"output_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  # Bu satÄ±r eksikse hiÃ§bir ÅŸey iÅŸlenmez!\n",
    "\n",
    "# === Ä°ÅLEME FONKSÄ°YONU ===\n",
    "def preprocess_dataset(data, image_folder, output_folder=\"processed_images\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    processed_data = {}\n",
    "\n",
    "    for word, frames in data.items():\n",
    "        processed_paths = []\n",
    "        print(f\"ğŸ“¦ Kelime iÅŸleniyor: {word}\")\n",
    "        for frame_info in frames:\n",
    "            img_path = os.path.join(image_folder, os.path.basename(frame_info[\"image_path\"]))\n",
    "            print(f\"ğŸ“‚ Dosya kontrol ediliyor: {img_path} - Var mÄ±? {os.path.exists(img_path)}\")\n",
    "            if os.path.exists(img_path):\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (256, 256))\n",
    "                anime_img = animegan(img)\n",
    "                print(\"âœ¨ AnimeGan filtresi uygulandÄ±\")\n",
    "                save_path = os.path.join(output_folder, f\"{word}_{len(processed_paths)}.jpg\")\n",
    "                cv2.imwrite(save_path, anime_img)\n",
    "                processed_paths.append(save_path)\n",
    "\n",
    "        processed_data[word] = processed_paths\n",
    "\n",
    "    with open(\"processed_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"âœ… GÃ¶rseller baÅŸarÄ±yla iÅŸlendi ve 'processed_data.json' dosyasÄ±na kaydedildi.\")\n",
    "\n",
    "# === FONKSÄ°YON Ã‡AÄRISI ===\n",
    "preprocess_dataset(data, \"OutputImages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a000073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "\n",
    "# === TÃ¼rkÃ§e Karakter Normalizasyon Fonksiyonu ===\n",
    "def normalize_text(text):\n",
    "    replacements = {\n",
    "        \"Ã§\": \"c\", \"ÄŸ\": \"g\", \"Ä±\": \"i\", \"Ã¶\": \"o\", \"ÅŸ\": \"s\", \"Ã¼\": \"u\",\n",
    "        \"Ã‡\": \"C\", \"Ä\": \"G\", \"Ä°\": \"I\", \"Ã–\": \"O\", \"Å\": \"S\", \"Ãœ\": \"U\"\n",
    "    }\n",
    "    for turkish_char, ascii_char in replacements.items():\n",
    "        text = text.replace(turkish_char, ascii_char)\n",
    "    return text\n",
    "\n",
    "# JSON'dan iÅŸlenmiÅŸ veri yÃ¼kleme\n",
    "with open(\"processed_data.json\", \"r\") as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# GÃ¶rÃ¼ntÃ¼leri baÅŸtan belleÄŸe al\n",
    "cached_frames = {}\n",
    "for word, paths in processed_data.items():\n",
    "    cached_frames[word] = [cv2.imread(p) for p in paths]\n",
    "\n",
    "def real_time_sign_language():\n",
    "    words_queue = []\n",
    "    stop_listening = threading.Event()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Kamera aÃ§Ä±lamadÄ±.\")\n",
    "        return\n",
    "\n",
    "    # Pencere ayarlarÄ±\n",
    "    screen_width = 3000\n",
    "    screen_height = 1200\n",
    "    cv2.namedWindow(\"Ä°ÅŸaret Dili Animasyonu\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Ä°ÅŸaret Dili Animasyonu\", screen_width, screen_height)\n",
    "    cv2.moveWindow(\"Ä°ÅŸaret Dili Animasyonu\", 0, 0)\n",
    "\n",
    "    def listen_microphone():\n",
    "        recognizer = sr.Recognizer()\n",
    "        mic = sr.Microphone()\n",
    "\n",
    "        with mic as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        while not stop_listening.is_set():\n",
    "            with mic as source:\n",
    "                try:\n",
    "                    print(\" KonuÅŸabilirsiniz...\")\n",
    "                    audio = recognizer.listen(source, timeout=3, phrase_time_limit=5)\n",
    "                    text = recognizer.recognize_google(audio, language=\"tr-TR\")\n",
    "                    words = text.split()\n",
    "                    if words:\n",
    "                        normalized_words = [normalize_text(w).capitalize() for w in words]\n",
    "                        words_queue.extend(normalized_words)\n",
    "                        print(f\" AlgÄ±landÄ±: {' '.join(normalized_words)}\")\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\" AnlaÅŸÄ±lamadÄ±, lÃ¼tfen tekrar edin...\")\n",
    "                except sr.RequestError:\n",
    "                    print(\" API hatasÄ±, internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.\")\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    threading.Thread(target=listen_microphone, daemon=True).start()\n",
    "\n",
    "    print(\" Kamera baÅŸlatÄ±ldÄ±. KonuÅŸtuÄŸunuz kelimelerin iÅŸaret dilini gÃ¶sterecek. Ã‡Ä±kmak iÃ§in 'q' tuÅŸuna basÄ±n...\")\n",
    "\n",
    "    current_word = \"\"\n",
    "    frame_list = []\n",
    "    last_word = \"\"\n",
    "    word_start_time = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Aynalama kaldÄ±rÄ±ldÄ± (flip yok)\n",
    "        user_frame = cv2.resize(frame, (screen_width, screen_height))\n",
    "        anime_frame = np.zeros((500, 500, 3), dtype=np.uint8)\n",
    "\n",
    "        # Yeni kelime kuyruÄŸu varsa ve animasyon yoksa\n",
    "        if words_queue and not frame_list:\n",
    "            current_word = words_queue.pop(0)\n",
    "            if current_word in cached_frames:\n",
    "                frame_list = cached_frames[current_word]\n",
    "                word_start_time = time.time()\n",
    "                last_word = current_word  # Son kelimeyi gÃ¼ncelle\n",
    "            else:\n",
    "                print(f\" Veri bulunamadÄ±: {current_word}\")\n",
    "                frame_list = []\n",
    "\n",
    "        # Animasyon varsa zamanla gÃ¶ster\n",
    "        if frame_list:\n",
    "            frame_count = len(frame_list)\n",
    "            elapsed_time = (time.time() - word_start_time) * 75\n",
    "            index = int(elapsed_time)\n",
    "\n",
    "            if index < frame_count:\n",
    "                anime_frame = cv2.resize(frame_list[index], (500, 500))\n",
    "            else:\n",
    "                frame_list = []\n",
    "        elif last_word in cached_frames:\n",
    "            # EÄŸer yeni kelime algÄ±lanmadÄ±ysa, son kelimenin ilk karesi gÃ¶sterilsin\n",
    "            anime_frame = cv2.resize(cached_frames[last_word][0], (500, 500))\n",
    "\n",
    "        # Anime frame'i saÄŸ alt kÃ¶ÅŸeye yerleÅŸtir\n",
    "        x_offset = screen_width - 500 - 20\n",
    "        y_offset = screen_height - 500 - 20\n",
    "        user_frame[y_offset:y_offset + 500, x_offset:x_offset + 500] = anime_frame\n",
    "\n",
    "        cv2.imshow(\"Ä°ÅŸaret Dili Animasyonu\", user_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            stop_listening.set()\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\" Sistem durduruldu.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7782748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kamera baÅŸlatÄ±ldÄ±. KonuÅŸtuÄŸunuz kelimelerin iÅŸaret dilini gÃ¶sterecek. Ã‡Ä±kmak iÃ§in 'q' tuÅŸuna basÄ±n...\n",
      " KonuÅŸabilirsiniz...\n",
      " AlgÄ±landÄ±: Merhaba\n",
      " KonuÅŸabilirsiniz...\n",
      " KonuÅŸabilirsiniz...\n",
      " AlgÄ±landÄ±: Ben\n",
      " KonuÅŸabilirsiniz...\n",
      " AlgÄ±landÄ±: Universite\n",
      " KonuÅŸabilirsiniz...\n",
      " AnlaÅŸÄ±lamadÄ±, lÃ¼tfen tekrar edin...\n",
      " KonuÅŸabilirsiniz...\n",
      " AlgÄ±landÄ±: Ogrencisiyim\n",
      " KonuÅŸabilirsiniz...\n",
      " AlgÄ±landÄ±: Simdi Proje Gelistiriyorum\n",
      " KonuÅŸabilirsiniz...\n",
      " AnlaÅŸÄ±lamadÄ±, lÃ¼tfen tekrar edin...\n",
      " KonuÅŸabilirsiniz...\n",
      " KonuÅŸabilirsiniz...\n",
      " KonuÅŸabilirsiniz...\n",
      " KonuÅŸabilirsiniz...\n",
      " KonuÅŸabilirsiniz...\n",
      " AlgÄ±landÄ±: Uzmanlar Uyarildi\n",
      " KonuÅŸabilirsiniz...\n",
      " KonuÅŸabilirsiniz...\n",
      " Sistem durduruldu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AnlaÅŸÄ±lamadÄ±, lÃ¼tfen tekrar edin...\n"
     ]
    }
   ],
   "source": [
    "# CanlÄ± sistem baÅŸlat\n",
    "real_time_sign_language()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
